{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2402e1be-d090-4c80-bc68-37de7019bdbe",
   "metadata": {},
   "source": [
    "# Use Case and Model  Life cycle Governance with SageMaker Model Registry resource sharing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99a17a5-e6b6-44c6-9523-deeef3d9fd25",
   "metadata": {},
   "source": [
    "## ML Flow Experimentation with Shared Model Group"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797eaf34-3a57-4e9d-b889-d00e45307d76",
   "metadata": {},
   "source": [
    "### 0. Pre-requisites: Access Model Package Groups in Shared Services account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b452ba-8d6e-4847-b556-cb94035b3404",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U -r requirements.txt\n",
    "\n",
    "# restart kernel\n",
    "import IPython\n",
    "IPython.Application.instance().kernel.do_shutdown(True) #automatically restarts kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33bb009-12cb-48f2-957e-d33d1a305cb1",
   "metadata": {},
   "source": [
    "Before you get started, check if there are any pending invitations from the shared services account \n",
    "and accept them. \n",
    "This will allow you to discover share model package groups and register your model versions against them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e336f791",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set required parameters used in cells below\n",
    "# Hub / Shared Account ID\n",
    "hub_account_id = 'AWS_ACCOUNT_ID'\n",
    "# Region used in the Hub account deployments\n",
    "hub_region = 'AWS_REGION'\n",
    "# KMS Key id deployed in the Hub account\n",
    "hub_kms_key_id = 'KMS_KEY_ID'\n",
    "# S3 bucket name created in the Hub account (The template HubS3BucketName parameter value)\n",
    "hub_s3_bucket_name = 'HubS3BucketName parameter value used in Cloudformation'\n",
    "\n",
    "# derive KMS key ARN\n",
    "hub_kms_key_arn = 'arn:aws:kms:{hub_region}:{hub_account_id}:key/{hub_kms_key_id}'.format(\n",
    "    hub_account_id=hub_account_id,\n",
    "    hub_region=hub_region,\n",
    "    hub_kms_key_id=hub_kms_key_id\n",
    ")\n",
    "\n",
    "# set the s3 bucket full name\n",
    "hub_s3_bucket = 'sagemaker-{hub_region}-{hub_account_id}-{hub_s3_bucket_name}'.format(\n",
    "    hub_region=hub_region,\n",
    "    hub_account_id=hub_account_id,\n",
    "    hub_s3_bucket_name=hub_s3_bucket_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3bc54e-25fa-42b9-8f65-96b3d5c5c0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "ram_client = boto3.client('ram')\n",
    "response = ram_client.get_resource_share_invitations()\n",
    "pending_invitations = []\n",
    "# Review all pending invitations\n",
    "for i in response['resourceShareInvitations']:\n",
    "    if i['status'] == \"PENDING\":\n",
    "        pending_invitations.append(i)\n",
    "print(pending_invitations,sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e619676-fba5-4ed7-9dd8-89ec03f5f8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accept the resource share invitation from shared services account\n",
    "if pending_invitations:\n",
    "    response = ram_client.accept_resource_share_invitation(resourceShareInvitationArn=pending_invitations[0]['resourceShareInvitationArn'])\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037be53d-1fdf-492e-8fee-3b1e06f95b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update the shared model bucket name here from the shared services account\n",
    "shared_model_bucket_name = hub_s3_bucket\n",
    "\n",
    "from botocore.client import ClientError\n",
    "import boto3\n",
    "s3_client = boto3.resource('s3')\n",
    "bucket = s3_client.Bucket(shared_model_bucket_name)\n",
    "try:\n",
    "    s3_client.meta.client.head_bucket(Bucket=shared_model_bucket_name)\n",
    "    print(\"The bucket \"+shared_model_bucket_name+\" exists and you have access.\")\n",
    "except ClientError:\n",
    "    print(\"The bucket \"+shared_model_bucket_name+\" does not exist or you have no access.\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a203f918-2816-47c0-a1fd-860d9da7b9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify your KMS key ID here\n",
    "# Update the ARN of the KMS Key Id from Shared Services Account \n",
    "kms_key_id = hub_kms_key_arn # 'your-kms-key-id' \n",
    "\n",
    "kms_client = boto3.client('kms')\n",
    "try:\n",
    "    response = kms_client.describe_key(\n",
    "        # An identifier for the KMS key. You can use the key ID, key ARN, alias name, alias ARN of the KMS key.\n",
    "        KeyId=kms_key_id,\n",
    "    )\n",
    "    print(\"The KMS \"+kms_key_id+\" key exists and you have access.\")\n",
    "except ClientError:\n",
    "    print(\"The KMS key \"+kms_key_id+\" does not exist or you have no access.\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217dc156-c320-4074-9591-97702df67410",
   "metadata": {},
   "source": [
    "### 1. Set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0851774-d325-4df2-82d4-8ff693823224",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import mlflow\n",
    "import pandas as pd\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "def get_domain_id():\n",
    "    try:\n",
    "        sagemaker_client = boto3.client('sagemaker')\n",
    "        domains = sagemaker_client.list_domains()\n",
    "        if domains['Domains']:\n",
    "            return domains['Domains'][0]['DomainId']\n",
    "        else:\n",
    "            print(\"No SageMaker domains found.\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving domain ID: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# SageMaker session and bucket setup\n",
    "sagemaker_session = sagemaker.Session()\n",
    "bucket_name = sagemaker_session.default_bucket()\n",
    "prefix = \"mlflow-credit-risk\"\n",
    "\n",
    "sagemaker_client = boto3.client(\"sagemaker\")\n",
    "\n",
    "s3_root_folder = f\"s3://{bucket_name}/{prefix}\"\n",
    "\n",
    "# Get domain ID programmatically\n",
    "domain_id = get_domain_id()\n",
    "if domain_id is None:\n",
    "    print(\"Warning: Unable to retrieve domain ID. Some functionality may be limited.\")\n",
    "\n",
    "role = get_execution_role(sagemaker_session)\n",
    "\n",
    "# Print configuration for verification\n",
    "print(f\"Using S3 bucket: {bucket_name}\")\n",
    "print(f\"Shared model bucket: {shared_model_bucket_name}\")\n",
    "print(f\"MLflow prefix: {prefix}\")\n",
    "print(f\"SageMaker Domain ID: {domain_id}\")\n",
    "print(f\"S3 root folder for MLflow: {s3_root_folder}\")\n",
    "print(f\"IAM role: {role}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4cebec-18e7-4b55-a296-79f0bf050519",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_running_mlflow_server(sagemaker_client, status_filter=['Created', 'Creating', 'Started']):\n",
    "    for status in status_filter:\n",
    "        servers = sagemaker_client.list_mlflow_tracking_servers(TrackingServerStatus=status)['TrackingServerSummaries']\n",
    "        if servers:\n",
    "            server = servers[0]\n",
    "            print(f\"Found an MLflow server {server['TrackingServerArn']} in the status '{status}'.\")\n",
    "            return server['TrackingServerArn'], server['TrackingServerName']\n",
    "    print(\"No MLflow servers found.\")\n",
    "    return None, None\n",
    "\n",
    "def create_mlflow_server(sagemaker_client, bucket_name, sm_role, domain_id):\n",
    "    \"\"\"\n",
    "    Creates a new MLflow server and returns its ARN and name.\n",
    "    \"\"\"\n",
    "    from time import strftime, gmtime\n",
    "    timestamp = strftime('%d-%H-%M-%S', gmtime())\n",
    "    mlflow_name = f\"mlflow-{domain_id}-{timestamp}\"\n",
    "    response = sagemaker_client.create_mlflow_tracking_server(\n",
    "        TrackingServerName=mlflow_name,\n",
    "        ArtifactStoreUri=f\"s3://{bucket_name}/mlflow/{timestamp}\",\n",
    "        RoleArn=sm_role,\n",
    "        AutomaticModelRegistration=True,\n",
    "    )\n",
    "\n",
    "    mlflow_arn = response['TrackingServerArn']\n",
    "    print(f\"Server creation request succeeded. The server {mlflow_arn} is being created.\")\n",
    "    return mlflow_arn, mlflow_name\n",
    "\n",
    "# Get a running MLflow server or create a new one if none exists\n",
    "mlflow_arn, mlflow_name = get_running_mlflow_server(sagemaker_client)\n",
    "if not mlflow_arn:\n",
    "    mlflow_arn, mlflow_name = create_mlflow_server(sagemaker_client, bucket_name, role, domain_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78b2876-3f01-446a-a1df-b53968b13cb2",
   "metadata": {},
   "source": [
    "### 2. Prepare the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0bb4a5a-378c-4fa1-9574-e09f3be454f8",
   "metadata": {},
   "source": [
    "The code was adapted from this repository https://github.com/aws-samples/amazon-sagemaker-credit-risk-prediction-explainability-bias-detection/tree/main"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7503178",
   "metadata": {},
   "source": [
    "#### UCI Machine Learning Repository Data Usage Disclaimer\n",
    "\n",
    "Before proceeding with any code execution or data download, please read and acknowledge the following:\n",
    "\n",
    "#### Disclaimer\n",
    "\n",
    "The following code and any datasets it may download or use adhere to the UCI Machine Learning Repository citation policy. This includes properly citing both the UCI Machine Learning Repository itself and any relevant papers associated with specific datasets. No modification or distribution of UCI datasets is permitted without proper authorization.\n",
    "\n",
    "#### Confirmation\n",
    "\n",
    "Please confirm that you have read and agree to these terms before proceeding\n",
    "\n",
    "If agree continue to with copying url https://archive.ics.uci.edu/static/public/573/south+german+credit+update.zip and replace in the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83af3b87-dac6-426c-855e-bf117ddb4272",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download and extract the dataset\n",
    "!mkdir -p data\n",
    "!rm -rf data/*\n",
    "!wget -N --no-check-certificate #replace-url-here\n",
    "!unzip south+german+credit+update.zip -d data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4fd216-6bce-49bf-ac67-879b683eba0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_columns = [\n",
    "    \"status\",\n",
    "    \"duration\",\n",
    "    \"credit_history\",\n",
    "    \"purpose\",\n",
    "    \"amount\",\n",
    "    \"savings\",\n",
    "    \"employment_duration\",\n",
    "    \"installment_rate\",\n",
    "    \"personal_status_sex\",\n",
    "    \"other_debtors\",\n",
    "    \"present_residence\",\n",
    "    \"property\",\n",
    "    \"age\",\n",
    "    \"other_installment_plans\",\n",
    "    \"housing\",\n",
    "    \"number_credits\",\n",
    "    \"job\",\n",
    "    \"people_liable\",\n",
    "    \"telephone\",\n",
    "    \"foreign_worker\",\n",
    "    \"credit_risk\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e24bb3-e513-4177-bd2b-cadba18043a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = pd.read_csv(\n",
    "    \"data/SouthGermanCredit.asc\",\n",
    "    names=credit_columns,\n",
    "    header=0,\n",
    "    sep=r\" \",\n",
    "    engine=\"python\",\n",
    "    na_values=\"?\",\n",
    ").dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738f5037-d6aa-41b0-ba13-85fbe4a03ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = training_data.sample(frac=0.1, random_state=42)\n",
    "test_data = test_data.drop(\"credit_risk\", axis=1)\n",
    "test_columns = [\n",
    "    \"status\",\n",
    "    \"duration\",\n",
    "    \"credit_history\",\n",
    "    \"purpose\",\n",
    "    \"amount\",\n",
    "    \"savings\",\n",
    "    \"employment_duration\",\n",
    "    \"installment_rate\",\n",
    "    \"personal_status_sex\",\n",
    "    \"other_debtors\",\n",
    "    \"present_residence\",\n",
    "    \"property\",\n",
    "    \"age\",\n",
    "    \"other_installment_plans\",\n",
    "    \"housing\",\n",
    "    \"number_credits\",\n",
    "    \"job\",\n",
    "    \"people_liable\",\n",
    "    \"telephone\",\n",
    "    \"foreign_worker\",\n",
    "]\n",
    "\n",
    "training_data.to_csv(\"train.csv\", index=False, header=True, columns=credit_columns)\n",
    "test_data.to_csv(\"test.csv\", index=False, header=True, columns=test_columns)\n",
    "\n",
    "# save the datasets in S3 for future use\n",
    "train_s3_url = sagemaker.Session().upload_data(\n",
    "    path=\"train.csv\",\n",
    "    bucket=bucket_name,\n",
    "    key_prefix=f\"{prefix}/input\"\n",
    ")\n",
    "print(f\"Upload the dataset to {train_s3_url}\")\n",
    "\n",
    "test_s3_url = sagemaker.Session().upload_data(\n",
    "    path=\"test.csv\",\n",
    "    bucket=bucket_name,\n",
    "    key_prefix=f\"{prefix}/input\"\n",
    ")\n",
    "print(f\"Upload the dataset to {test_s3_url}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a891cc9-739f-4914-9612-188dae543823",
   "metadata": {},
   "source": [
    "### 3. Process the data with Amazon SageMaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083060ba-0ff3-4b7b-8077-de11cf31e913",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import gmtime, strftime, sleep\n",
    "\n",
    "experiment_suffix = strftime('%d-%H-%M-%S', gmtime())\n",
    "registered_model_name = f\"credit-risk-model-{experiment_suffix}\"\n",
    "experiment_name = f\"credit-risk-model-experiment-{experiment_suffix}\"\n",
    "print(experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119a2eab-9165-40f2-b0ab-88a614542137",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tarfile\n",
    "import sklearn\n",
    "import joblib\n",
    "import mlflow\n",
    "from sagemaker.s3 import S3Uploader\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.compose import make_column_transformer\n",
    "\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "from sagemaker.remote_function import remote\n",
    "\n",
    "\n",
    "# use spot instances\n",
    "# @remote(s3_root_uri=f\"s3://{bucket_name}/{prefix}\", dependencies=f\"requirements.txt\", instance_type=\"ml.m5.large\", use_spot_instances=True, max_wait_time_in_seconds=3600, max_runtime_in_seconds=3600)\n",
    "# use ondemand instances\n",
    "@remote(s3_root_uri=f\"s3://{bucket_name}/{prefix}\", dependencies=f\"requirements.txt\", instance_type=\"ml.m5.large\")\n",
    "def preprocess(df, experiment_name, mlflow_arn, bucket_name, prefix, run_id=None):\n",
    "    \"\"\"\n",
    "    Preprocess the input data and split it into training and validation sets.\n",
    "\n",
    "    Args:\n",
    "        df (pandas.DataFrame): Input data.\n",
    "        experiment_name (str): Name of the MLflow experiment.\n",
    "        run_id (str, optional): MLflow run ID. If not provided, a new run will be created.\n",
    "        mlflow_arn (str, optional): MLflow tracking URI.\n",
    "        s3_root_folder (str, optional): S3 root folder for remote execution.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the training and validation features and labels.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        mlflow.set_tracking_uri(mlflow_arn)\n",
    "        suffix = strftime('%d-%H-%M-%S', gmtime())\n",
    "        mlflow.set_experiment(experiment_name=experiment_name if experiment_name else f\"credit-risk-model-experiment-{suffix}\")\n",
    "        run = mlflow.start_run(run_id=run_id) if run_id else mlflow.start_run(run_name=f\"remote-processing-{suffix}\", nested=True)\n",
    "\n",
    "        output_path = \"/opt/ml/output/data\"\n",
    "        os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "        print(\"Reading input data\")\n",
    "        model_dataset = mlflow.data.from_pandas(df)\n",
    "        mlflow.log_input(model_dataset, context=\"model_dataset\")\n",
    "\n",
    "        print(\"Performing one-hot encoding\")\n",
    "        categorical_cols = [\n",
    "            \"credit_history\",\n",
    "            \"purpose\",\n",
    "            \"personal_status_sex\",\n",
    "            \"other_debtors\",\n",
    "            \"property\",\n",
    "            \"other_installment_plans\",\n",
    "            \"housing\",\n",
    "            \"job\",\n",
    "            \"telephone\",\n",
    "            \"foreign_worker\",\n",
    "        ]\n",
    "        transformer = make_column_transformer(\n",
    "            (OneHotEncoder(sparse_output=False), categorical_cols),\n",
    "            remainder=\"passthrough\",\n",
    "        )\n",
    "\n",
    "        print(\"Preparing features and labels\")\n",
    "        X = df.drop(\"credit_risk\", axis=1)\n",
    "        y = df[\"credit_risk\"]\n",
    "\n",
    "        print(\"Building scikit-learn transformer\")\n",
    "        featurizer_model = transformer.fit(X)\n",
    "        features = featurizer_model.transform(X)\n",
    "        labels = LabelEncoder().fit_transform(y)\n",
    "\n",
    "        split_ratio = 0.3\n",
    "        print(f\"Splitting data into train and validation sets with ratio {split_ratio}\")\n",
    "        X_train, X_val, y_train, y_val = train_test_split(\n",
    "            features, labels, test_size=split_ratio, random_state=0\n",
    "        )\n",
    "\n",
    "        print(f\"Train features shape after preprocessing: {X_train.shape}\")\n",
    "        print(f\"Validation features shape after preprocessing: {X_val.shape}\")\n",
    "\n",
    "        mlflow.log_params({\"train_shape\": X_train.shape, \"val_shape\": X_val.shape})\n",
    "\n",
    "        train_features_path = os.path.join(output_path, \"train_features.csv\")\n",
    "        print(f\"Saving training features to {train_features_path}\")\n",
    "        pd.DataFrame(X_train).to_csv(train_features_path, header=False, index=False)\n",
    "\n",
    "        train_labels_path = os.path.join(output_path, \"train_labels.csv\")\n",
    "        print(f\"Saving training labels to {train_labels_path}\")\n",
    "        pd.DataFrame(y_train).to_csv(train_labels_path, header=False, index=False)\n",
    "\n",
    "        val_features_path = os.path.join(output_path, \"val_features.csv\")\n",
    "        print(f\"Saving validation features to {val_features_path}\")\n",
    "        pd.DataFrame(X_val).to_csv(val_features_path, header=False, index=False)\n",
    "\n",
    "        val_labels_path = os.path.join(output_path, \"val_labels.csv\")\n",
    "        print(f\"Saving validation labels to {val_labels_path}\")\n",
    "        pd.DataFrame(y_val).to_csv(val_labels_path, header=False, index=False)\n",
    "\n",
    "        model_dir = \"/opt/ml/model\"\n",
    "        os.makedirs(model_dir, exist_ok=True)\n",
    "        model_path = os.path.join(model_dir, \"model.joblib\")\n",
    "        model_output_path = os.path.join(model_dir, \"model.tar.gz\")\n",
    "\n",
    "        print(f\"Saving featurizer model to {model_output_path}\")\n",
    "        joblib.dump(featurizer_model, model_path)\n",
    "        with tarfile.open(model_output_path, \"w:gz\") as tar:\n",
    "            tar.add(model_path, arcname=\"model.joblib\")\n",
    "\n",
    "        mlflow.sklearn.log_model(\n",
    "            sk_model=featurizer_model,\n",
    "            artifact_path=\"processing/model\",\n",
    "            registered_model_name=\"sk-learn-model\",\n",
    "        )  \n",
    "        return X_train, X_val, y_train, y_val\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Exception in processing script: {e}\")\n",
    "        raise e\n",
    "    finally:\n",
    "        mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd46deed-bd1f-49b4-8390-39660d7e1a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"train.csv\", names=None, header=0, sep=\",\")\n",
    "X_train, X_val, y_train, y_val = preprocess(df, experiment_name, mlflow_arn, bucket_name, prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e396da74-4f92-4dcb-bbf0-0b786dc50d5e",
   "metadata": {},
   "source": [
    "### 4. Model training with SageMaker training jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c88ab6-a48c-4efc-b477-7b06f6ea043f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import pickle as pkl\n",
    "import os\n",
    "import mlflow\n",
    "import tarfile\n",
    "\n",
    "# use spot instances\n",
    "# @remote(s3_root_uri=f\"s3://{bucket_name}/{prefix}\", dependencies=f\"requirements.txt\", instance_type=\"ml.m5.large\", use_spot_instances=True, max_wait_time_in_seconds=3600, max_runtime_in_seconds=3600)\n",
    "# use ondemand instances\n",
    "@remote(s3_root_uri=f\"s3://{bucket_name}/{prefix}\", dependencies=f\"requirements.txt\", instance_type=\"ml.m5.large\")\n",
    "def train(X, val_X, y, val_y, num_round, params, mlflow_arn, experiment_name,run_id=None):\n",
    "    output_path = \"/opt/ml/model\"\n",
    "    mlflow.set_tracking_uri(mlflow_arn)\n",
    "    mlflow.autolog()\n",
    "    \n",
    "    suffix = strftime('%d-%H-%M-%S', gmtime())\n",
    "    mlflow.set_experiment(experiment_name=experiment_name if experiment_name else f\"credit-risk-model-experiment-{suffix}\")\n",
    "    run = mlflow.start_run(run_id=run_id) if run_id else mlflow.start_run(run_name=f\"remote-training-{suffix}\", nested=True)\n",
    "\n",
    "    try:\n",
    "        os.makedirs(output_path, exist_ok=True)\n",
    "        print(f\"Directory '{output_path}' created successfully.\")\n",
    "    except OSError as e:\n",
    "        print(f\"Error creating directory '{output_path}': {e}\")\n",
    "        \n",
    "    dtrain = xgboost.DMatrix(X, label=y)\n",
    "    dval = xgboost.DMatrix(val_X, label=val_y)\n",
    "\n",
    "    dtrain = xgboost.DMatrix(X, label=y)\n",
    "    dval = xgboost.DMatrix(val_X, label=val_y)\n",
    "\n",
    "    watchlist = [(dtrain, \"train\"), (dval, \"validation\")]\n",
    "    mlflow.log_params(params)\n",
    "\n",
    "    print(\"Training the model\")\n",
    "    evaluation__results = {}\n",
    "    bst = xgboost.train(\n",
    "        params=params, dtrain=dtrain, evals=watchlist, num_boost_round=num_round\n",
    "    )\n",
    "    pkl.dump(bst, open(output_path + \"/model.bin\", \"wb\"))\n",
    "\n",
    "     # Compress the model.bin artifact to a tar file\n",
    "    tar_filename = f\"{output_path}/model.tar.gz\"\n",
    "    with tarfile.open(tar_filename, \"w:gz\") as tar:\n",
    "        tar.add(f\"{output_path}/model.bin\", arcname=\"model.bin\")\n",
    "\n",
    "# Upload the compressed model to S3\n",
    "\n",
    "    s3_client = boto3.client(\"s3\")\n",
    "    s3_key = f\"{prefix}/model_{run.info.run_id}.tar.gz\"\n",
    "    \n",
    "    s3_client.upload_file(tar_filename,\n",
    "        shared_model_bucket_name,\n",
    "        s3_key,\n",
    "        ExtraArgs={\n",
    "            'ServerSideEncryption': 'aws:kms',\n",
    "            'SSEKMSKeyId': kms_key_id\n",
    "        }\n",
    "    )\n",
    "\n",
    "    mlflow.log_artifact(local_path=tar_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea9d73a-407d-4f40-be13-9cc2262639c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    \"max_depth\": \"5\",\n",
    "    \"eta\": \"0.1\",\n",
    "    \"gamma\": \"4\",\n",
    "    \"min_child_weight\": \"6\",\n",
    "    \"silent\": \"1\",\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"num_round\": \"100\",\n",
    "    \"subsample\": \"0.8\",\n",
    "    \"eval_metric\": \"auc\"\n",
    "}\n",
    "num_round = 50\n",
    "\n",
    "train(X_train, X_val, y_train, y_val,num_round, hyperparameters, mlflow_arn, experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b63c7ba-9cc9-48d1-ba16-9fddf6df1be3",
   "metadata": {},
   "source": [
    "### 5. Register your the candidate model to the model registry in the shared services account"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a822d92-0c3e-46c5-9077-0b2217cdb00f",
   "metadata": {},
   "source": [
    "Now register the trained model in the MLflow model registry. The model is also automatically registered in the SageMaker model registry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa308f0-e9c2-462c-9740-b2bcf9965c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(mlflow_arn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d384f3-6f57-411c-8c55-cc32e9270b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_experiments = mlflow.search_experiments(\n",
    "    # filter_string=\"tags.`project_name` = 'credit-risk-model-experiment-22-06-27-27'\"\n",
    ")\n",
    "check_experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e3323d-6ff8-43d3-a0ec-854f9da3e0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.entities import ViewType\n",
    "\n",
    "run_filter = f\"\"\"\n",
    "attributes.run_name LIKE \"%training%\"\n",
    "attributes.status = 'FINISHED'\n",
    "\"\"\"\n",
    "runs_with_filter = mlflow.search_runs(\n",
    "    experiment_names=[experiment_name],\n",
    "    run_view_type=ViewType.ACTIVE_ONLY,\n",
    "    filter_string=run_filter,\n",
    "    order_by=[\"metrics.`validation-auc` DESC\"],\n",
    ")\n",
    "best_run = runs_with_filter[:1]\n",
    "\n",
    "display(best_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3d92f4-8edf-416c-844e-96a657d193a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "# Assuming best_run is a pandas DataFrame with one row\n",
    "if not best_run.empty:\n",
    "    run_id = best_run.iloc[0]['run_id']  # Get the run_id from the first row\n",
    "\n",
    "    # Fetch the full run data\n",
    "    full_run = mlflow.get_run(run_id)\n",
    "\n",
    "    # Access run data\n",
    "    run_data = full_run.data\n",
    "    params = run_data.params\n",
    "    metrics = run_data.metrics\n",
    "\n",
    "    # Display parameters\n",
    "    display(\"Parameters:\")\n",
    "    for key, value in params.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "\n",
    "    # Display metrics\n",
    "    display(\"\\nMetrics:\")\n",
    "    for key, value in metrics.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "\n",
    "    # Display run info\n",
    "    display(\"\\nRun Info:\")\n",
    "    run_info = full_run.info\n",
    "    for attr in dir(run_info):\n",
    "        if not attr.startswith(\"_\"):  # Skip private attributes\n",
    "            value = getattr(run_info, attr)\n",
    "            if not callable(value):  # Skip methods\n",
    "                print(f\"{attr}: {value}\")\n",
    "\n",
    "    # Display tags if any\n",
    "    if full_run.data.tags:\n",
    "        display(\"\\nTags:\")\n",
    "        for key, value in full_run.data.tags.items():\n",
    "            print(f\"{key}: {value}\")\n",
    "else:\n",
    "    display(\"No best run found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ed430f-392d-4b0e-8f3e-4cc3053dfcaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "artifact_uri = best_run['artifact_uri'][0]\n",
    "print(artifact_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9374f3bf-9abf-4f9a-863b-1379c02d5450",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = sagemaker_client.list_model_package_groups(CrossAccountFilterOption=\"CrossAccount\")\n",
    "model_package_group_name = response['ModelPackageGroupSummaryList'][0]['ModelPackageGroupName']\n",
    "print(\"model_package_group_name:\",model_package_group_name)\n",
    "model_package_group_arn = response['ModelPackageGroupSummaryList'][0]['ModelPackageGroupArn']\n",
    "print(\"model_package_group_arn:\",model_package_group_arn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707b32b2-d6b0-4e5f-81c0-fd0f1e8cae83",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{artifact_uri}/model/model.tar.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af86839-c5ca-4034-8888-bd6da1423144",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import json\n",
    "\n",
    "# Assuming the training has been completed and MLflow has logged the run\n",
    "# Get the most recent run (or you can specify a run_id if you know it)\n",
    "runs = mlflow.search_runs(experiment_ids=[mlflow.get_experiment_by_name(experiment_name).experiment_id])\n",
    "best_run = runs.iloc[0]  # Get the most recent run\n",
    "\n",
    "# Print the run ID\n",
    "print(f\"Best run ID: {best_run.run_id}\")\n",
    "\n",
    "s3_key = f\"{prefix}/model_{best_run.run_id}.tar.gz\"\n",
    "print(f\"s3://{shared_model_bucket_name}/{s3_key}\")\n",
    "\n",
    "# Now, let's update the model card with the information from this run\n",
    "# Now create the model card content\n",
    "# The information entered here is key to model governance tracking table\n",
    "model_card_content = {\n",
    "    \"model_overview\": {\n",
    "        \"model_creator\": \"XGBoost Training Team\",\n",
    "        \"model_artifact\": [f\"s3://{shared_model_bucket_name}/{s3_key}\"]  # You need to define s3_bucket and s3_key\n",
    "    },\n",
    "    \"intended_uses\": {\n",
    "        \"purpose_of_model\": \"Credit risk assessment\",\n",
    "        \"intended_uses\": \"Evaluate creditworthiness of loan applicants\",\n",
    "        \"factors_affecting_model_efficiency\": \"Data quality, economic conditions, regulatory changes\",\n",
    "        \"risk_rating\": \"Medium\",\n",
    "        \"explanations_for_risk_rating\": \"Model deals with sensitive financial data and decisions\"\n",
    "    },\n",
    "    \"business_details\": {\n",
    "        \"business_problem\": \"Improve accuracy and efficiency of credit risk assessment\",\n",
    "        \"business_stakeholders\": \"Credit department, Risk management team, Compliance officers\",\n",
    "        \"line_of_business\": \"Consumer Lending\"\n",
    "    },\n",
    "    \"training_details\": {\n",
    "        \"objective_function\": {\n",
    "            \"function\": \"Maximize\",\n",
    "            \"notes\": \"XGBoost objective function used for training\"\n",
    "        },\n",
    "        \"training_observations\": \"Model trained using XGBoost with early stopping\"\n",
    "    },\n",
    "    \"additional_information\": {\n",
    "        \"ethical_considerations\": \"Ensure fair lending practices, avoid discriminatory outcomes\",\n",
    "        \"caveats_and_recommendations\": \"Regular monitoring for model drift, periodic retraining with updated data\",\n",
    "        \"custom_details\": {\n",
    "            \"UseCaseId\": \"CREDIT-001\",\n",
    "            \"UseCaseName\": \"Credit Risk Assessment\",\n",
    "            \"UseCaseStage\": \"Development\"\n",
    "        }\n",
    "    }\n",
    "\n",
    "}\n",
    "\n",
    "# Save the model card\n",
    "with open('model_card.json', 'w') as f:\n",
    "    json.dump(model_card_content, f, indent=2)\n",
    "print(model_card_content)\n",
    "print(\"Model card has been created and saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55ae1bf-fa55-4d5e-8b5f-db7a7e3fd5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "region = boto3.Session().region_name\n",
    "container = sagemaker.image_uris.retrieve(\n",
    "    framework='xgboost',\n",
    "    region=region,\n",
    "    version='1.0-1',\n",
    "    py_version='py3',\n",
    "    instance_type='ml.m5.xlarge'\n",
    ")\n",
    "container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e480501-54a6-4576-8700-afdf838c8497",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11: Create a model package\n",
    "\n",
    "# CHECK ARN IN SHARED MODEL PACKAGE GROUPS AND REPLACE\n",
    "\n",
    "model_package_input_dict = {\n",
    "    \"ModelPackageGroupName\": model_package_group_arn,\n",
    "    \"ModelPackageDescription\": \"Credit Risk - Initial version\",\n",
    "    \"ModelApprovalStatus\": \"PendingManualApproval\",\n",
    "    \"InferenceSpecification\": {\n",
    "        \"Containers\": [\n",
    "            {\n",
    "                \"Image\": container,\n",
    "                \"ModelDataUrl\": f\"s3://{shared_model_bucket_name}/{s3_key}\"\n",
    "            }\n",
    "        ],\n",
    "        \"SupportedContentTypes\": [\"text/csv\"],\n",
    "        \"SupportedResponseMIMETypes\": [\"text/csv\"]\n",
    "    },\n",
    "    # \"ModelMetrics\": {\n",
    "    #     \"ModelQuality\": {\n",
    "    #         \"Statistics\": {\n",
    "    #             \"S3Uri\": f's3://{bucket}/{prefix}/metrics/iris_model_metrics.json',\n",
    "    #             \"ContentType\": 'application/json'\n",
    "    #         }\n",
    "    #     }\n",
    "    # },\n",
    "    \"ModelCard\": {\n",
    "        \"ModelCardContent\": json.dumps(model_card_content),\n",
    "        \"ModelCardStatus\": \"Draft\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e35a9e1-508d-49fa-8b9e-02f6d05e5ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelpackage_package_specification =  {\n",
    "    \"ModelPackageGroupName\" : model_package_group_arn,\n",
    "    \"ModelPackageDescription\" : \"Model to detect credit risk\",\n",
    "    \"ModelApprovalStatus\" : \"PendingManualApproval\",\n",
    "    \"ModelCard\": {\n",
    "        \"ModelCardContent\": json.dumps(model_card_content),\n",
    "        \"ModelCardStatus\": \"Draft\"\n",
    "    }\n",
    "}\n",
    "\n",
    "create_model_package_input_dict = {\n",
    "    \"ModelPackageGroupName\" : model_package_group_arn,\n",
    "    \"ModelPackageDescription\" : \"Model to detect credit risk\",\n",
    "    \"ModelApprovalStatus\" : \"PendingManualApproval\"\n",
    "}\n",
    "\n",
    "create_model_package_input_dict.update(modelpackage_package_specification)\n",
    "\n",
    "create_model_package_input_dict.update(model_package_input_dict)\n",
    "\n",
    "print(create_model_package_input_dict)\n",
    "create_model_package_response = sagemaker_client.create_model_package(**create_model_package_input_dict)\n",
    "##model_package_arn = create_model_package_response[\"ModelPackageArn\"]\n",
    "#print('ModelPackage Version ARN : {}'.format(model_package_arn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086f971d-addf-4ad0-a7d1-71af73ae29d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create_model_package_response = sagemaker_client.create_model_package(**create_model_package_input_dict)\n",
    "model_package_arn = create_model_package_response[\"ModelPackageArn\"]\n",
    "print('ModelPackage Version ARN : {}'.format(model_package_arn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d65cc9-3f92-416c-81fe-85ae9cd0d751",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update Model Lifecycle\n",
    "import boto3\n",
    "import json\n",
    "\n",
    "print(\"Boto3 version:\", boto3. __version__)\n",
    "\n",
    "def update_model_lifecycle(model_package_info, model_package_update_input_dict):\n",
    "    sagemaker_client = boto3.client('sagemaker')\n",
    "    try:\n",
    "\n",
    "         # Extract the ARN from the model_package_info\n",
    "        model_package_arn = model_package_info.get('ModelPackageArn')\n",
    "        \n",
    "        if not model_package_arn:\n",
    "            raise ValueError(\"ModelPackageArn not found in the provided information\")\n",
    "\n",
    "        # Ensure ModelPackageArn is in the input dictionary\n",
    "        model_package_update_input_dict['ModelPackageArn'] = model_package_arn\n",
    "        response = sagemaker_client.update_model_package(**model_package_update_input_dict)\n",
    "        \n",
    "        print(f\"Model lifecycle updated successfully for {model_package_arn}\")\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        print(f\"Error updating model lifecycle: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Update Model Cycle Info\n",
    "\n",
    "model_package_info = {\n",
    "    'ModelPackageGroupName': model_package_group_arn,\n",
    "    'ModelPackageArn': model_package_arn,\n",
    "}\n",
    "\n",
    "# Update the staging values as needed for your projects\n",
    "# cfr https://docs.aws.amazon.com/sagemaker/latest/dg/model-registry-staging-construct-set-up.html\n",
    "\n",
    "model_package_update_input_dict = {\n",
    "    'ModelLifeCycle': {\n",
    "        'Stage': 'Development',\n",
    "        'StageDescription': 'Model trained and evaluated in development environment',\n",
    "        'StageStatus': 'Approved' # PendingApproval/Approved/Rejected\n",
    "    },\n",
    "}\n",
    "\n",
    "result = update_model_lifecycle(model_package_info, model_package_update_input_dict)\n",
    "\n",
    "if result:\n",
    "    print(\"Update successful\")\n",
    "    print(json.dumps(result, indent=2))\n",
    "else:\n",
    "    print(\"Update failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d312f1e5-8027-4b12-ab9d-db7c7a251392",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
